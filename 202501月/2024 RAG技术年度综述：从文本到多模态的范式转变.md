2024年注定是RAG技术蓬勃发展的一年。回顾这一年，我们不难发现，RAG之所以能够取得如此巨大的进步，离不开业界在多个关键领域的不懈探索和创新。

![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843506050-87c74ed3-0e2d-4dc0-8726-76a8bda6fba6.png)

## 多模态文档解析的突破
![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843727930-1f36e0fd-a7e5-4745-9039-95f04a621fa4.png)

让我们先来看看多模态文档解析领域。传统的RAG系统主要面向纯文本数据，但在实际应用中，大量的企业数据以PDF、PPT等非结构化、多模态形式存在。

这就好比你的个人电脑，里面除了Word文档，是否还有大量的图片、视频、幻灯片等其他形式的文件？要想高效管理和检索这些异构数据，单靠纯文本处理是远远不够的。

这时，文档智能（Document Intelligence）技术的出现犹如一道曙光。它利用先进的视觉模型，可以精准识别文档版面，提取关键信息。

就以PaddleOCR为例，它不仅可以从图片中识别出文字，还能进一步分析文字的版面结构，提取段落、表格等关键元素。**<font style="color:#117CEE;">PaddleOCR采用了一种端到端的视觉文档理解范式，通过联合训练OCR引擎和版面分析引擎，实现了对图像和PDF等非结构化文档的“一键式”解析</font>****。**

其中，版面分析引擎是PaddleOCR的一大亮点。它首先利用一个CNN骨干网提取出图像的视觉特征，然后通过一系列可微分的几何操作如RoIAligh和RoISlide，将视觉特征投影到文本区域，提取局部特征序列。

最后，版面分析引擎使用一个递归神经网络对局部特征序列进行自回归建模，输出各个文本区域的位置、类别和层次结构信息。与传统的两阶段算法相比，PaddleOCR的端到端方法大大简化了处理流程，且文本检测和识别精度达到了SOTA水平。

**<u><font style="color:#2F4BDA;">RAGFlow的DeepDoc模块进一步把PaddleOCR与RAG系统做了无缝集成。它不仅支持常见的中英文场景，还专门针对代码、公式、表格等特殊区域做了识别优化。</font></u>**

此外，DeepDoc还设计了一套灵活的数据增强策略，可以模拟多种扫描和拍摄场景下的噪声、模糊、透视畸变等，大幅提升了模型的泛化性能。实测表明，DeepDoc能够高精度地还原PDF、图片等多模态文档的原始信息和结构，进而为后续的信息抽取和检索提供高质量的输入。

设想一下，当你在RAG系统中检索“2024年Q1财报”时，系统不仅能返回相关的文本片段，还能突出显示报表中的关键数字，甚至还能生成报表的缩略图预览。

这种多模态的搜索结果，无疑能够极大提升信息获取的效率和体验。可以说，多模态文档解析能力已经成为RAG系统的标配，它必将引领RAG在企业级应用中走得更远。

## 混合检索策略的创新
![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843294760-64bdb156-2b36-4839-939f-10e9fb6f85b2.png)

接下来我们再聊聊混合检索。RAG系统要想在海量数据中快速、准确地匹配到用户需要的信息，仅靠单一的向量检索显然是不够的。因为向量更擅长捕捉语义层面的相似性，但对于字面匹配往往无能为力。

打个比方，假设用户想要查询“Anthropic公司的创始人是谁”，仅用向量检索可能会返回一些与人工智能、初创公司相关的文档，但未必能直接命中答案。这就是我们常说的查全率和命中率问题。为了解决这一问题，学界和业界在过去一年达成了共识：**<u><font style="color:#117CEE;">RAG系统需要采用多管齐下的混合检索策略。</font></u>**

<font style="color:#2F4BDA;">以往的语义匹配模型大多基于Transformer等神经网络架构，采用自注意力机制来建模query和doc的交互。这类模型虽然效果拔群，但推理开销大，很难应用到实时排序中。</font>

今年由Dima Krotov等人提出的ColBERT彻底颠覆了这一格局。ColBERT巧妙地将query-doc交互矩阵分解为query向量和doc向量的外积，并通过采样近似来加速矩阵乘法。这使得ColBERT能在亚毫秒级别的延迟下实现高质量的语义排序。

检索时只需用query的embedding与doc张量做内积，即可高效而精准地评估它们的相关性。借助现代张量计算框架的加持，能轻松扩展到百亿规模的语料，且性能远超传统的倒排索引和向量检索方法。

在工程实践上，**基于张量的语义检索能力已经被多个RAG引擎实装落地。典型的如Milvus、Jina AI等开源向量数据库都已支持张量数据类型和张量计算，用户可以直接把预计算的doc embedding导入系统。**

而阿里云等商业平台更进一步将张量检索封装成即插即用的云服务，让开发者以极低的成本享受到最新的语义检索技术。

值得一提的是，RAGFlow在此基础上还进行了精巧的Query分析，自动提取用户问句中的关键词组合，生成短语查询，大幅提升了检索的准确率。

比如当用户问“Tom去年的KPI完成得如何”，RAGFlow会自动生成多个短语查询，如“Tom KPI”、“KPI 完成”等，多管齐下确保不漏掉任何相关线索。可以预见，混合检索将成为未来RAG系统的“标配”，而BM25等经典全文检索算法也将重放异彩。

## 排序模型的进化
**<u>RAG系统中的 Reranker 模块扮演着至关重要的角色，它能够优化检索结果，提高最相关文档的排序。Reranker 作为信息检索系统中的第二遍文档过滤器，主要关注根据查询-文档相关性重新排序由初始检索器（如语义搜索、关键字搜索等）检索到的文档。</u>**

我们需要 Reranker 的主要原因在于它能够**帮助解决幻觉问题并节省 RAG 过程中的成本**。传统的 Embedding 方法面临着语义理解有限、维度约束和泛化问题等挑战，难以充分满足实际检索需求。而 Reranker 则通过采用 Bag-of-Embeddings 方法、语义关键字匹配以及更好的泛化能力，从根本上克服了 Embedding 的局限性。

**<font style="color:#117CEE;">当前主流的 Reranker 类型包括：Cross-Encoder、Multi-Vector Reranker、基于 LLM 的 Reranker、有监督学习的 LLM Reranker 以及私有的 Reranking API。</font>**

其中，Cross-Encoder 模型采用数据对的分类机制，而不是传统的向量 Embedding，能够更细致地理解数据点之间的关系。ColBERT 等 Multi-Vector Embedding 模型则通过延迟查询和文档表示之间的交互，允许预计算文档表示，加快检索速度并降低计算复杂度。

近年来，随着 LLM 规模的不断扩大，fine-tuning Reranking 模型变得愈发具有挑战性。研究者们尝试通过 Prompting 的方式让 LLM 自主改进文档重排序，<u>主要策略可分为 Pointwise、Listwise 和 Pairwise 三类</u>。

此外，有监督学习的 LLM Reranker 通过在特定任务的 Ranking 数据集上进行 fine-tuning，让 LLM 调整参数以改善 Reranking 性能。这类 Reranker 可further 分为 Encoder-Decoder 和 Decoder-only 两种架构。

除了开源和学术界的 Reranker 模型外，一些商业公司也推出了私有的 Reranking API，如 <u>Cohere、Jina 和 Mixedbread</u>，为组织提供了方便的语义相关性解决方案。在选择 Reranker 时，需要综合考虑相关性改进、延迟、上下文理解能力和泛化能力等多个因素。

最新的研究比较了不同 Reranker 方法的有效性和效率，尤其是与强大的 Retriever 如 SPLADEv3 结合使用时的表现。

研究表明，<u>有效的 Cross-Encoder 配合强 Retriever 能够在 Reranking 任务上超越大多数 LLM，同时效率更高。而尽管基于 LLM 的 zero-shot Reranker 展现出不俗的性能，但效率低下和高成本限制了其实际应用。</u>

## GraphRAG：跨越语义鸿沟
![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843353939-b47dd341-874d-420f-b6e0-eb52cf2b1f07.png)

说到语义鸿沟，这是RAG系统的一大痛点。<u>所谓语义鸿沟，就是用户的问句和knowledge base中的碎片化知识很难直接对应。尤其是当用户问一些跨片段、需要综合推理的问题时，传统的RAG系统往往难以应对。</u>

好在今年的GraphRAG等一系列工作给出了一个全新的思路：与其被动地填补鸿沟，不如主动地“搭桥”。**<u>GraphRAG利用先进的大模型，从文档中自动抽取出命名实体及其关系，建立起一张语义丰富的知识图谱。</u>**

这相当于在原本割裂的知识碎片之间建立了一座座“桥梁”。当用户问一些开放式的问题，如“Anthropic的业务发展如何”，GraphRAG不仅能召回相关的实体如“Anthropic”、“人工智能”、“创始人”等，还能根据知识图谱中的边和社区结构进行拓展。比如它能找到“Anthropic”->“总部”->“旧金山湾区”这样一条路径，据此生成更加全面的答案。

后续的RARE等工作进一步引入主动推理机制，通过大模型自动拆解用户问题，生成子查询，多轮迭代优化检索结果。这就好比RAG系统拥有了自己的“大脑”，能像人一样主动思考，不断询问和论证，最终得出令人信服的答案。

毋庸置疑，GraphRAG及其变体必将成为RAG系统的“杀手锏”，它们和张量Rerank等技术的结合，有望彻底打通知识获取的“最后一公里”。

## Agent与内存管理的演进
![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843403396-95338385-96a7-4d2c-bb51-dc7111029400.png)

Agent和内存管理也是今年的一大热点。随着RAG系统逐渐从单纯的问答工具发展为用户的“私人助理”，如何赋予其更强的主动意识和上下文记忆就成了一个关键课题。

这里的Agent并非简单的对话机器人，而是一个能够主动分析用户需求、提供个性化服务的智能助手。而内存管理则让Agent能够在多轮对话中保持语境，根据用户的身份和偏好给出差异化的答案。

举个例子，假设你是一家公司的CEO，你的RAG助理应该能够记住你的身份，在你问“公司上个季度的营收情况如何”时，自动关联你最关心的核心指标；而当你问“竞品公司X最新的产品动态”时，它应该能主动去搜集竞品信息，生成一份有洞见的分析报告。这种个性化、主动式的服务，才是Agent的终极形态。

从这个意义上说，**<font style="color:#117CEE;">Agent其实是赋予了RAG一双“慧眼”和一个“灵魂”。有了内存管理和主动分析能力，RAG系统才能真正理解用户，而不仅仅停留在机械地匹配。</font>**

可以期待，随着Mem0等项目的发展，以及工业级认知智能框架如CoT和ToT的引入，Agent将在未来表现出更加惊艳的“智慧”。

## 多模态RAG的新探索
![](https://cdn.nlark.com/yuque/0/2025/png/406504/1736843457673-50e50fc0-7ed4-4ac5-9781-a003bcd4fba2.png)

多模态RAG则代表了一个全新的探索方向。<u>随着CLIP、BLIP等多模态预训练模型的成熟，RAG系统已经具备了直接理解图像、视频等非文本信息的能力。ColPali等项目进一步探索了如何用统一的张量Rerank来实现真正的跨模态检索排序。</u>

想象一下，也许在不久的将来，你只需对着手机说一句“帮我找一下上周会议上Tom分享的那个'公司愿景'PPT”，RAG系统就能自动定位到相关的幻灯片，并智能提取其中的关键信息，甚至以更加生动、易于理解的方式呈现给你。

这种**<u>“格式无关”的知识服务，将极大拓展RAG的应用边界</u>**。随着更多多模态模型的开源，以及RAG专用数据库对多维向量索引的原生支持，我们有理由相信，多模态RAG将在未来迎来爆发式增长。

但多模态RAG要真正落地，还面临诸多技术挑战。其中之一是**<u><font style="color:#DF2A3F;">如何用统一的向量表示来编码不同模态的语义，以实现跨模态的低成本检索</font></u>**。

ColPali等项目在这方面做了有益探索。ColPali将每幅图像划分为固定数量的patch，然后用CLIP分别提取图像patch和文本token的embedding，再通过优化一个对比学习目标来对齐它们在共同语义空间中的分布。

检索时，ColPali先用图文的patch embedding建立倒排索引；对输入的query，它用同样的CLIP模型提取token embedding，然后在索引中查找最相关的图像patch。实验表明，ColPali在跨模态检索的效果和效率上都有不俗的表现。

要进一步提升多模态RAG的性能，还需要在视觉语言理解的基础模型上下功夫。OpenAI新发布的GPT4就展现了惊艳的“看图说话”能力。它不仅能准确地解读图像内容，对一些细节的敏感度甚至超过人眼，更能结合场景做出合理的推断和联想。

这得益于GPT4采用的全新的多模态对比预训练范式，它将图文对齐的任务拆解为两个子问题：用图像去retrieve最匹配的文本，用文本去retrieve最匹配的图像。

通过这种匹配-生成的迭代式训练，GPT4学会了深度融合视觉语言特征，形成了更鲁棒、更泛化的多模态语义表示。相信未来会有越来越多的RAG系统选择GPT4这样强大的多模态基座，去实现更智能、更自然的人机交互。

## 总结展望
<u>从OCR、GNN到CLIP、GPT4，这些看似割裂的碎片正在被一个个RAG系统“编织”成智能时代的新花样。它们让RAG从浅层的语义匹配，进化到深层的认知推理；从单一的文本处理，拓展到多模态的感知交互。</u>如今的RAG已然具备了“知识+推理+感知”的全栈能力，它正以智能助手的身份渗透到零售、制造、金融、医疗等各行各业，提供个性化、主动式的知识服务。

当然，RAG要成为真正通用、高效的智能基础设施，还有不少难题需要攻克。比如知识的自动化获取、语义向量的动态更新、认知推理的可解释性等，都亟待产学研用各界给出系统性的解决方案。

