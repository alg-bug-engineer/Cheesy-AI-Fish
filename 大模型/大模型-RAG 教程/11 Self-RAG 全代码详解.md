# 11. Self-RAG å…¨ä»£ç è¯¦è§£

ä¸çœ‹å†…å®¹è¦ä»£ç ç‰ˆï¼š[å®˜æ–¹Repo](https://github.com/AkariAsai/self-rag/tree/main)

å¦‚ä½•è®©å¤§è¯­è¨€æ¨¡å‹æ›´åŠ çœŸå®ã€æ­£ç¡®ã€å¯é ï¼Ÿ

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ï¼Œä¾‹å¦‚å¹»è§‰å’Œç¼ºä¹æœ€æ–°çŸ¥è¯†ã€‚

ç„¶è€Œï¼Œå¦‚æœä½ å·²ç»å°è¯•è¿‡ RAGï¼Œå¯èƒ½ä¼šæœ‰ç›¸åŒçš„æ„Ÿå—ï¼Œé‚£å°±æ˜¯RAGä¸Šæ‰‹å®¹æ˜“ï¼Œä½†å¾ˆéš¾è¾¾åˆ°å¯ç”¨çš„æ°´å¹³ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è®¨è®ºä¸€ç¯‡å…³äºSelf-RAGçš„æ–°ç ”ç©¶[è®ºæ–‡](https://arxiv.org/abs/2310.11511)ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æé«˜ RAG æ¨¡å‹æ€§èƒ½çš„æ–°æ–¹æ³•ï¼š

- ğŸš€ Self-RAG 7B åœ¨ 6/8 ä»»åŠ¡ä¸Šä¼˜äº ChatGPT 3.5
- ğŸš€ åœ¨äº‹å®æ£€æŸ¥ä»»åŠ¡ä¸­å‡†ç¡®ç‡è¾¾åˆ° 81%

# Self-RAGæ˜¯ä»€ä¹ˆï¼Ÿ

RAG æ•ˆç‡åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ–‡æœ¬åˆ†å—æ–¹æ³•ã€åµŒå…¥å’Œæ£€ç´¢æŠ€æœ¯ç­‰å› ç´ ã€‚

å½“ä¸åŠ é€‰æ‹©åœ°æ£€ç´¢å›ºå®šæ•°é‡çš„æ®µè½æˆ–è·å–ä¸ç›¸å…³çš„å†…å®¹æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸æ­£ç¡®çš„ç»“æœï¼Œå¾—åˆ°RAGåœ¨å½“åœºå‰åœºä¸å¯ç”¨çš„ç»“è®ºã€‚

2023 å¹´ 10 æœˆï¼Œä¸€ç¯‡é¢˜ä¸ºã€ŠSelf-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflectionã€‹çš„æ–°ç ”ç©¶è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªåˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æŒ‡å¯¼LLMä½•æ—¶æ£€ç´¢æ¥æé«˜LLMçš„ä¸€è‡´æ€§å’Œè¡¨ç°ã€‚

å®éªŒè¡¨æ˜ï¼ŒSelf-RAGï¼ˆ7B å’Œ 13B å‚æ•°ï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸Šæ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„ LLMï¼ˆä¾‹å¦‚ ChatGPT å’Œ Llama2-chatï¼‰å’Œæ£€ç´¢å¢å¼ºæ¨¡å‹ã€‚

# Self-RAGï¼šæ•™LLMä½•æ—¶æ£€ç´¢

è‡ªæˆ‘åæ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆSelf-RAGï¼‰æ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œæ•™å¯¼LLMæ£€ç´¢ã€ç”Ÿæˆå’Œæ‰¹åˆ¤ï¼Œä»¥æé«˜å…¶å›ç­”çš„çœŸå®æ€§å’Œè´¨é‡ã€‚

ä¸ä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ–¹æ³•ç›¸æ¯”ï¼ŒSelf-RAG æŒ‰éœ€æ£€ç´¢ä¿¡æ¯ï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥æ ¹æ®é‡åˆ°çš„æŸ¥è¯¢å¤šæ¬¡æ£€ç´¢æˆ–æ ¹æœ¬ä¸æ£€ç´¢ã€‚

å®ƒè¿˜ä½¿ç”¨ç§°ä¸ºâ€œåå°„ä»¤ç‰Œâ€çš„ç‰¹æ®Šä»¤ç‰Œä»å„ä¸ªè§’åº¦è¯„ä¼°å…¶å“åº”ã€‚è¿™äº›ä»¤ç‰Œå…è®¸ LLM åœ¨æ¨ç†é˜¶æ®µæ§åˆ¶å…¶è¡Œä¸ºå¹¶æ ¹æ®ç‰¹å®šä»»åŠ¡è¦æ±‚è¿›è¡Œå®šåˆ¶ã€‚

![https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645459-5038e607-22f5-4918-8c89-f459127beffb.png](https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645459-5038e607-22f5-4918-8c89-f459127beffb.png)

Self-RAGæ ¹æ®ä¸åŒçš„æŸ¥è¯¢æŒ‰éœ€æ£€ç´¢ï¼ˆä¾‹å¦‚ï¼Œå¯ä»¥æ£€ç´¢å¤šæ¬¡æˆ–å®Œå…¨è·³è¿‡æ£€ç´¢ï¼‰ï¼Œå¹¶è¯„ä»·å…¶è‡ªå·±çš„ç”Ÿæˆã€‚

# Self-RAG çš„å†…éƒ¨è¿ä½œ

Self-RAG æ–¹æ³•çš„æ ¸å¿ƒæ˜¯é€šè¿‡â€œè‡ªæˆ‘åæ€æ ‡è®°â€æ¥æ•™å¯¼å’Œæ§åˆ¶å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) ã€‚è¿™ä¸ªè¿‡ç¨‹å‘ç”Ÿåœ¨æ¨ç†é˜¶æ®µï¼Œå³LLMç”Ÿæˆå“åº”çš„æ—¶å€™ã€‚

ä»¥ä¸‹æ˜¯ Self-RAG çš„å·¥ä½œåŸç†ï¼š

1. æ£€ç´¢ï¼šSelf-RAG é¦–å…ˆç¡®å®šå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯æ·»åŠ åˆ°å“åº”ä¸­æ˜¯å¦ä¼šæœ‰å¸®åŠ©ã€‚å¦‚æœæ˜¯ï¼Œåˆ™å®ƒå‘å‡ºæ£€ç´¢è¿‡ç¨‹çš„ä¿¡å·ï¼Œå¹¶è¦æ±‚å¤–éƒ¨æ£€ç´¢æ¨¡å—æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£ã€‚
2. ç”Ÿæˆï¼šå¦‚æœä¸éœ€è¦æ£€ç´¢ï¼ŒSelf-RAG ä¼šé¢„æµ‹å“åº”çš„ä¸‹ä¸€éƒ¨åˆ†ï¼Œå°±åƒå¸¸è§„è¯­è¨€æ¨¡å‹ä¸€æ ·ã€‚å¦‚æœéœ€è¦æ£€ç´¢ï¼Œå®ƒé¦–å…ˆè¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ç›¸å…³ï¼Œç„¶åæ ¹æ®å‘ç°çš„å†…å®¹ç”Ÿæˆå“åº”çš„ä¸‹ä¸€éƒ¨åˆ†ã€‚
3. è¯„ä»·ï¼šå¦‚æœéœ€è¦æ£€ç´¢ï¼ŒSelf-RAG ä¼šæ£€æŸ¥æ£€ç´¢åˆ°çš„æ®µè½æ˜¯å¦æ”¯æŒå“åº”ã€‚å®ƒè¿˜è¯„ä¼°å“åº”çš„æ•´ä½“è´¨é‡ã€‚

# Self-RAGçš„è®­ç»ƒè¿‡ç¨‹

Self-RAG è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ï¼Œè¯„è®ºå®¶å’Œç”Ÿæˆè€…ï¼Œä¸¤è€…éƒ½ä½¿ç”¨åå°„æ ‡è®°æ‰©å±•æ ‡è®°è¯æ±‡è¡¨ï¼Œå¹¶ä½¿ç”¨æ ‡å‡†çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚

- ç¬¬ 1 æ­¥ Critic æ•°æ®åˆ›å»ºï¼šé€šè¿‡æç¤º GPT-4 ç”Ÿæˆåå°„æ ‡è®°æ¥ç”Ÿæˆ Critic è®­ç»ƒæ•°æ®ã€‚
- æ­¥éª¤ 2 Critic è®­ç»ƒï¼šåœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒ Critic æ¨¡å‹ã€‚
- æ­¥éª¤ 3 ç”Ÿæˆå™¨æ•°æ®åˆ›å»ºï¼šä½¿ç”¨ Critic å’Œ Retriever ç”Ÿæˆç”Ÿæˆå™¨è®­ç»ƒæ•°æ®ã€‚
- ç¬¬ 4 æ­¥ç”Ÿæˆå™¨è®­ç»ƒï¼šåœ¨ RAG æ•°æ®é›†ä¸Šè®­ç»ƒç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬ç”¨äºæ•™å¯¼æ¨¡å‹ä½•æ—¶æ£€ç´¢æˆ–ä¸æ£€ç´¢çš„ç‰¹æ®Šæ ‡è®°ã€‚

# åº”ç”¨Self-RAG

# ä½¿ç”¨ Self-RAG è¿è¡Œæ¨ç†

Self-RAG æ¨¡å‹åœ¨åŸºç¡€æ¨¡å‹ Llama-2â€“7b-hf ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œç°å·²åœ¨ Hugging Face ä¸Šæä¾›ã€‚

ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨ Self-RAG è¿è¡Œæ¨ç†ã€‚

1. å®‰è£…å¿…è¦çš„åŒ…

```
!pip  install  vllm
!pip  install  torch
!pip  install  Transformers,  tokenizer,  datasets,  peft,  Bitsandbytes
!pip  install  Accelerator>=0.21.0,<0.23.0
!pip  install  peft>=0.4.0
!pip  installvaluate  >=0.4.0
!pip  install  tiktoken
```

2. è¿è¡Œæ¨ç†

æŒ‰ç…§ç ”ç©¶å›¢é˜Ÿçš„å»ºè®®ä½¿ç”¨ vllm æ¥åŠ é€Ÿæ¨ç†ã€‚

```
# Import necessary libraries
from vllm import LLM, SamplingParams

# Initialize the LLM (Large Language Model) with the specified model and data type
model = LLM("selfrag/selfrag_llama2_7b", dtype="half")

# Define sampling parameters for text generation
sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=100, skip_special_tokens=False)

# Define a function to format prompts, including an instruction and an optional paragraph for retrieval
def format_prompt(input, paragraph=None):
  prompt = "### Instruction:\n{0}\n\n### Response:\n".format(input)
  if paragraph is not None:
    prompt += "[Retrieval]<paragraph>{0}</paragraph>".format(paragraph)
  return prompt

# Define two queries for the model to generate responses for
query_1 = "Leave odd one out: twitter, instagram, whatsapp."
query_2 = "Can you tell me the difference between llamas and alpacas?"
queries = [query_1, query_2]

# Generate responses for the queries
preds = model.generate([format_prompt(query) for query in queries], sampling_params)

# Print the model's predictions for each query
for pred in preds:
  print("\n\nModel prediction: {0}".format(pred.outputs[0].text))
```

æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ Self-RAG çš„è¾“å‡ºã€‚

æˆ‘ä»¬æ‰§è¡Œäº†ä¸¤ä¸ªæŸ¥è¯¢ï¼Œå¹¶è§‚å¯Ÿåˆ°å¯¹äºç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼ŒSelf-RAG ç›´æ¥ç”Ÿæˆå“åº”ï¼Œè€Œä¸æ£€ç´¢ä¿¡æ¯ï¼Œå› ä¸ºæ£€ç´¢æ˜¯ä¸å¿…è¦çš„ã€‚åœ¨ç¬¬äºŒä¸ªæŸ¥è¯¢ä¸­ï¼ŒSelf-RAG æ˜¾ç¤º [Retrieve] æ ‡è®°ï¼Œå› ä¸ºé—®é¢˜éœ€è¦æ›´å¤šäº‹å®ä¿¡æ¯ã€‚

![https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645265-60f32403-1e6e-40e9-a163-cdee8a96f181.png](https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645265-60f32403-1e6e-40e9-a163-cdee8a96f181.png)

ç¬¬ä¸€ä¸ªæŸ¥è¯¢æ²¡æœ‰æ£€ç´¢ï¼Œç¬¬äºŒä¸ªæŸ¥è¯¢æœ‰ä¿¡æ¯æ£€ç´¢ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

# ä½¿ç”¨è‡ªå·±çš„æ•°æ®è¿è¡Œ Self-RAG

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è‡ªå·±çš„æ•°æ®ä¸ Self-RAG äº¤äº’çš„ä¸¤ç§æ–¹æ³•ï¼š

1. ç›´æ¥æ•°æ®æ’å…¥ï¼šæœ€ç®€å•çš„æ–¹æ³•æ˜¯å°†æ•°æ®ç›´æ¥æ’å…¥åˆ°å‡½æ•°paragraphçš„å‚æ•°ä¸­format_promptã€‚è¿™ä½¿å¾— Self-RAG å¯ä»¥ç›´æ¥è®¿é—®ä½ çš„æ•°æ®å¹¶å°†å…¶åˆå¹¶åˆ°å…¶å“åº”ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚
2. åŸºäºåµŒå…¥çš„æ£€ç´¢ï¼šå¯¹äºæ›´å¤æ‚çš„æ•°æ®æˆ–ç›´æ¥æ’å…¥ä¸åˆ‡å®é™…çš„æƒ…å†µï¼Œå¯ä»¥ä¸ºæ•°æ®ç”ŸæˆåµŒå…¥ï¼Œå¹¶åˆ©ç”¨æ£€ç´¢æœºåˆ¶ä¸º Self-RAG æå–ç›¸å…³ä¿¡æ¯ã€‚è¿™ç§æ–¹æ³•ä½¿ Self-RAG èƒ½å¤Ÿæ ¹æ®æŸ¥è¯¢ä¸Šä¸‹æ–‡æœ‰é€‰æ‹©åœ°æ£€ç´¢å’Œåˆ©ç”¨æ•°æ®ä¸­çš„ä¿¡æ¯ã€‚

# ç›´æ¥æ•°æ®æ’å…¥

å¯¹äºéœ€è¦å¤–éƒ¨äº‹å®ä¾æ®çš„æŸ¥è¯¢ï¼Œå¯ä»¥æ’å…¥ä¸€ä¸ªæ®µè½ã€‚

Self-RAG å¯ä»¥åœ¨ç”Ÿæˆæ—¶éšæ—¶æ£€ç´¢å’Œæ’å…¥æ®µè½ï¼Œå¹¶ä¸”åªè¦å®ƒä»¬è¢«ä¸Šä¸‹æ–‡æ ‡è®°ç‰¹æ®Šæ ‡è®°åŒ…å›´å³å¯è¯†åˆ«å®ƒä»¬<paragraph>ã€‚</paragraph>

![https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645084-85890db7-650c-43a1-aead-87fe12cf07d4.png](https://cdn.nlark.com/yuque/0/2023/png/406504/1699872645084-85890db7-650c-43a1-aead-87fe12cf07d4.png)

é€šè¿‡â€œparagraphâ€å‚æ•°æ·»åŠ äº‹å®ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

# åŸºäºåµŒå…¥çš„æ£€ç´¢

å¯ä»¥åˆ©ç”¨åŸå§‹ç ”ç©¶è®ºæ–‡æä¾›çš„[è„šæœ¬å’Œä»£ç ](https://github.com/AkariAsai/self-rag/tree/main/retrieval_lm)å°†è‡ªå·±çš„æ•°æ®åˆå¹¶åˆ° Self-RAG ä¸­ã€‚è¯¥è¿‡ç¨‹æ¶‰åŠä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š

1. æ•°æ®å‡†å¤‡

ä»¥ JSON æˆ– JSONL æ ¼å¼å‡†å¤‡æ•°æ®é›†ã€‚æ¯ä¸ªå®ä¾‹åº”åŒ…å«ä¸€ä¸ªé—®é¢˜æˆ–ä¸€æ¡æŒ‡ä»¤ï¼Œè¿™å°†ä½œä¸ºæ£€ç´¢æœŸé—´çš„æŸ¥è¯¢ã€‚

2. åµŒå…¥ç”Ÿæˆ

ä½¿ç”¨ GitHub å­˜å‚¨åº“ä¸­æä¾›çš„è„šæœ¬ä¸ºæ‚¨çš„æ•°æ®ç”ŸæˆåµŒå…¥ã€‚è¿™ä¼šå°†ä½ çš„æ•°æ®è½¬æ¢ä¸ºå¯ç”±æ£€ç´¢æœºåˆ¶æœ‰æ•ˆå¤„ç†çš„æ•°å­—è¡¨ç¤ºå½¢å¼ã€‚

```
cd retrieval_lm
CUDA_VISIBLE_DEVICES=0

python generate_passage_embeddings.py  --model_name_or_path facebook/contriever-msmarco \
--output_dir [YOUR_OUTPUT_DIR] \
--passages [YOUR_PASSAGE_DATA] \
--shard_id 0  --num_shards 4 > ./log/nohup.my_embeddings 2>&1 &
```

3. å¯¹è‡ªå·±çš„æ•°æ®è¿è¡Œ Self-RAG

å°†ç”Ÿæˆçš„åµŒå…¥ä¸ Self-RAG çš„æ£€ç´¢æ¨¡å—ç›¸ç»“åˆï¼Œä»æ•°æ®ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚ç„¶åï¼ŒSelf-RAG å°†åˆ©ç”¨æ­¤ä¿¡æ¯ç”Ÿæˆé’ˆå¯¹ä½ çš„ç‰¹å®šæŸ¥è¯¢çš„å“åº”ã€‚

```
from passage_retriever import Retriever

retriever = Retriever({})
query = "YOUR_QUERY"
retriever.setup_retriever("facebook/contriever-msmarco", [YOUR_JSON_DATA_FILE], [YOUR_DATA_EMBEDDING],  n_docs=5, save_or_load_index=False)
retrieved_documents = retriever.search_document(query, 5)
prompts = [format_prompt(query, doc["title"] +"\n"+ doc["text"]) for doc in retrieved_documents]
preds = model.generate(prompts, sampling_params)
top_doc = retriever.search_document(query, 1)[0]
print("Reference: {0}\nModel prediction: {1}".format(top_doc["title"] + "\n" + top_doc["text"], preds[0].outputs[0].text))
```

# ä½¿ç”¨ Self-RAG å¢å¼º RAG Pipeline

æˆ–è€…ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Self-RAG æ–¹æ¡ˆè®­ç»ƒæ–°çš„é¢„è®­ç»ƒ LLMï¼Œä¾‹å¦‚ ChatGLM3-6bã€‚å®˜æ–¹ä»“åº“å·²ç»æä¾›äº†æ¯”è¾ƒå¥½ç”¨çš„å¾®è°ƒè®­ç»ƒ[è„šæœ¬](https://github.com/AkariAsai/self-rag/blob/main/retrieval_lm/script_finetune_7b.sh)ã€‚

# æœ€å

RAG å¯èƒ½ä¼šå¯¼è‡´ä¸æ°å½“çš„å“åº”ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­æ·»åŠ ç‰¹æ®Šæ ‡è®°å¯ä»¥æ•™å¯¼æ¨¡å‹ä½•æ—¶æ£€ç´¢ä¿¡æ¯ä»¥åŠç›¸å…³ä¿¡æ¯ã€‚

Self-RAG æ˜¯ä¸€ç§æœ‰è¶£çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²å¤§å‹è¯­è¨€æ¨¡å‹å¤ªå¤šåˆ›é€ æ€§å¤šåŠŸèƒ½æ€§çš„æƒ…å†µä¸‹æé«˜äº‹å®æ€§ã€‚å®ƒæ˜¾ç¤ºäº†è®©LLMåæ€è‡ªèº«å±€é™æ€§å¹¶æœ‰é€‰æ‹©åœ°è·å–çŸ¥è¯†çš„å¥½å¤„ã€‚

è®ºæ–‡ä¸­åˆ†äº«çš„æ¨¡å‹å·²ç»åœ¨ 150,000 ä¸ªå®ä¾‹çš„è¯„ä»·è€…è®­ç»ƒä¸­è¿›è¡Œäº†å¾®è°ƒã€‚è¿™æ˜¯ä¸€ä¸ªå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºæ£€ç´¢å’Œéæ£€ç´¢ç¤ºä¾‹çš„æ•°æ®é›†éƒ½éœ€è¦å¤šæ ·åŒ–ã€‚æœ€é…·çš„æ˜¯ï¼Œå®Œæ•´çš„æ•°æ®é›†å’Œä»£ç åœ¨ GitHub ä¸Šå®Œå…¨å…±äº«ï¼Œå› æ­¤å¯ä»¥å¾®è°ƒä»»æ„çš„è‡ªå®šä¹‰ LLMï¼Œä¾‹å¦‚ ChatGLM3-6bã€baichuanç­‰ã€‚